{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "from Gan import *\n",
    "import torch.nn as nn\n",
    "from data_loader import data_loader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5657,  0.1176, -0.5275],\n",
       "        [-0.5767,  0.3274,  1.0041]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_inputA=torch.rand(1,3,256,256)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1146, -0.2768, -0.7548])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=th.randn(3,)\n",
    "b=th.randn(3,3)\n",
    "def sim(z_i, z_j):\n",
    "    \"\"\"Normalized dot product between two vectors.\n",
    "\n",
    "    Inputs:\n",
    "    - z_i: 1xD tensor.\n",
    "    - z_j: 1xD tensor.\n",
    "    \n",
    "    Returns:\n",
    "    - A scalar value that is the normalized dot product between z_i and z_j.\n",
    "    \"\"\"\n",
    "    norm_dot_product = None\n",
    "    ##############################################################################\n",
    "    # TODO: Start of your code.                                                  #\n",
    "    #                                                                            #\n",
    "    # HINT: torch.linalg.norm might be helpful.                                  #\n",
    "    ##############################################################################\n",
    "    norm_dot_product=torch.matmul(z_i,z_j)/(torch.linalg.norm(z_i)*torch.linalg.norm(z_j))\n",
    "    \n",
    "    ##############################################################################\n",
    "    #                               END OF YOUR CODE                             #\n",
    "    ##############################################################################\n",
    "    \n",
    "    return norm_dot_product\n",
    "c=sim(a,b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01.png', '02.png', '03.png', '04.png', '05.png', '06.png', '07.png', '08.png', '09.png', '10.png', '11.png', '12.png', '13.png', '14.png', '15.png', '16.png', '17.png', '18.png', '19.png', '20.png', '21.png', '22.png', '23.png', '24.png', '25.png', '26.png', '27.png', '28.png', '29.png', '30.png', '31.png', '32.png', '33.png', '34.png', '35.png', '36.png', '37.png', '38.png', '39.png', '40.png', '41.png', '42.png']\n"
     ]
    }
   ],
   "source": [
    "class ARGS:\n",
    "    def __init__(self):\n",
    "        self.datapath=\"F:\\dataset\\multi_focus\"\n",
    "        self.init_size=32\n",
    "        self.final_size=128\n",
    "        self.device=th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "        self.adam_beta1=0.9\n",
    "        self.adam_beta2=0.999\n",
    "        self.g_lr=0.0001\n",
    "        self.d_lr=0.0004\n",
    "        self.generator_optim_file=None\n",
    "        self.discriminator_optim_file=None\n",
    "        self.loss_function=\"RelativeplusContentLoss\"\n",
    "        self.alpha=3\n",
    "        self.beta=2\n",
    "        self.num_epochs=1 #\n",
    "        self.checkpoint_factor=1#\n",
    "        self.feedback_factor=5#\n",
    "        self.data_percentage=100\n",
    "        self.num_samples=2#\n",
    "        self.sample_dir=\"F:/dataset/multi_focus/MSG-MFGAN/recordings/images\"\n",
    "        self.batch_size=1\n",
    "        self.start=1\n",
    "        self.loss_dir=\"F:/dataset/multi_focus/MSG-MFGAN/recordings/loss\"\n",
    "        self.model_dir=\"F:/dataset/multi_focus/MSG-MFGAN/recordings/model\"\n",
    "        \n",
    "        self.imgArootPath=\"C:/Users/forever/Desktop/学习\\学习/毕业/muti-focus/Evaluation-for-Image-Fusion-main/Image/Source-Image/TNO/ir\"\n",
    "        \n",
    "args=ARGS()        \n",
    "datapath=args.datapath\n",
    "init_size=args.init_size\n",
    "final_size=args.final_size\n",
    "device=args.device\n",
    "\n",
    "#get the data\n",
    "# data=data_loader.MultiFocusDataset(datapath,mode=\"train\",size=final_size)\n",
    "# data=DataLoader(data, batch_size=args.batch_size, shuffle=True)\n",
    "# testdata=data_loader.MultiFocusDataset(datapath,mode=\"test\",size=final_size)\n",
    "# testdata=DataLoader(testdata, batch_size=args.num_samples, shuffle=True)\n",
    "#get the MSG_MFGAN model\n",
    "msg_mfgan=Gan.MSG_MFGAN(init_size=init_size,final_size=final_size,device=device)\n",
    "msg_mfgan.generate_samples2(args.imgArootPath)\n",
    "# msg_mfgan.load(gen_path=\"recordings2\\model\\GAN_GEN_172.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('g_01_1.tif', 'g_01_2.tif'), ('g_02_1.tif', 'g_02_2.tif'), ('g_03_1.tif', 'g_03_2.tif'), ('g_04_1.tif', 'g_04_2.tif'), ('g_05_1.tif', 'g_05_2.tif'), ('g_06_1.tif', 'g_06_2.tif'), ('g_07_1.tif', 'g_07_2.tif'), ('g_08_1.tif', 'g_08_2.tif'), ('g_09_1.tif', 'g_09_2.tif'), ('g_10_1.tif', 'g_10_2.tif')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 指定目录路径\n",
    "dir_path = 'C:/Users/forever/Desktop/学习\\学习/毕业/muti-focus/MFIF-master\\sourceimages\\grayscale'\n",
    "def getFilepairs(dir_path):\n",
    "    # define prefix\n",
    "    prefix = 'g_'\n",
    "\n",
    "    # get all filenames\n",
    "    filenames = os.listdir(dir_path)\n",
    "\n",
    "    # filter image filenames\n",
    "    image_extensions = ['.tif']\n",
    "    image_filenames = [filename for filename in filenames if any(filename.endswith(ext) for ext in image_extensions)]\n",
    "\n",
    "    # get image pairs\n",
    "    image_pairs = []\n",
    "    for filename in image_filenames:\n",
    "        if filename.startswith(prefix):\n",
    "            suffix = filename.split('_')[-1]\n",
    "            if suffix == '1.tif':\n",
    "                pair_filename = filename[:-5] + '2.tif'\n",
    "                if pair_filename in image_filenames:\n",
    "                    image_pairs.append((filename, pair_filename))\n",
    "    return image_pairs\n",
    "\n",
    "\n",
    "print(getFilepairs(dir_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3,4,5]\n",
    "a[0:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c1479fbd218fb91649283905e033bcdb9a923f856519ef658834a14d3edcdf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
